import rasterio
import numpy as np
import os
from rasterio.warp import reproject, Resampling
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV
from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, classification_report
import pandas as pd
from imblearn.over_sampling import SMOTE
from scipy.stats import randint as sp_randint
import matplotlib.pyplot as plt

# Define the directory path where the files are located in Colab
data_dir = '/content/'

# List of files to be used in the model
files = [
    'SMI.tif', 'Slope_Degree.tif', 'Saturation.tif', 'Relief_Dissection.tif', 'Geomorphology.tif', 'Geology.tif', 'TPI.tif', 'Cicatrizes.tif'
]
cicatrizes_file = 'Cicatrizes.tif'

# Function to load and resample a raster to the reference shape
def load_resample_raster(file_path, shape_ref, transform_ref, crs_ref):
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"File not found: {file_path}")
    
    with rasterio.open(file_path) as src:
        data = src.read(1)
        if data.shape != shape_ref:
            out_data = np.empty(shape_ref, dtype=data.dtype)
            reproject(
                source=data,
                destination=out_data,
                src_transform=src.transform,
                src_crs=src.crs,
                dst_transform=transform_ref,
                dst_crs=crs_ref,
                resampling=Resampling.bilinear
            )
            print(f"Resampled {file_path} from {data.shape} to {shape_ref}")
            return out_data
        else:
            print(f"Loaded {file_path} with shape {data.shape}")
            return data

# Check if the files are present in the directory
print("Files available in the directory:")
print(os.listdir(data_dir))

# Load the reference layer (cicatrizes layer)
cicatrizes_path = os.path.join(data_dir, cicatrizes_file)
with rasterio.open(cicatrizes_path) as src:
    cicatrizes = src.read(1)
    reference_transform = src.transform
    reference_crs = src.crs
reference_shape = cicatrizes.shape

# Load and resample the other raster layers to the reference shape
layers = {}
for file in files:
    path = os.path.join(data_dir, file)
    if file != cicatrizes_file:  # No need to resample the cicatrizes layer
        data = load_resample_raster(path, reference_shape, reference_transform, reference_crs)
        layers[file] = data

# Prepare the input data for the model
rows, cols = reference_shape
X = np.zeros((rows * cols, len(layers)))

for i, (name, data) in enumerate(layers.items()):
    X[:, i] = data.ravel()

# Use the cicatrizes layer as the target variable
y = cicatrizes.ravel()

# Check the class distribution in y
unique, counts = np.unique(y, return_counts=True)
print(f"Class distribution in y: {dict(zip(unique, counts))}")

# Sample data to reduce processing time
sample_size = 5000  # Adjust the sample size as needed
indices = np.random.choice(X.shape[0], sample_size, replace=False)
X_sample = X[indices]
y_sample = y[indices]

# Split the data into training and testing sets, ensuring stratification
X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.3, random_state=42, stratify=y_sample)

# Check the class distribution in y_test
unique_test, counts_test = np.unique(y_test, return_counts=True)
print(f"Class distribution in y_test: {dict(zip(unique_test, counts_test))}")

# Apply SMOTE for class balancing
if len(np.unique(y_train)) > 1:  # Ensure there are at least two classes
    min_class_samples = np.min(np.bincount(y_train))  # Count the samples in the minority class
    n_neighbors = min(5, max(1, min_class_samples - 1))  # Dynamically adjust n_neighbors
    smote = SMOTE(random_state=42, k_neighbors=n_neighbors)
    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

    # Check the class distribution after SMOTE
    unique_train_balanced, counts_train_balanced = np.unique(y_train_balanced, return_counts=True)
    print(f"Class distribution in y_train after SMOTE: {dict(zip(unique_train_balanced, counts_train_balanced))}")
else:
    print("SMOTE not applied due to lack of class diversity.")
    X_train_balanced, y_train_balanced = X_train, y_train

# Set up stratified cross-validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Define hyperparameters for RandomizedSearchCV
param_dist_rf = {
    "n_estimators": sp_randint(10, 200),
    "max_depth": sp_randint(3, 20),
    "min_samples_split": sp_randint(2, 11),
    "min_samples_leaf": sp_randint(1, 11),
    "bootstrap": [True, False]
}

param_dist_gb = {
    "n_estimators": sp_randint(10, 200),
    "learning_rate": [0.01, 0.05, 0.1, 0.2],
    "max_depth": sp_randint(3, 20),
    "min_samples_split": sp_randint(2, 11),
    "min_samples_leaf": sp_randint(1, 11)
}

# Initialize models
models = {
    'Random Forest': RandomForestClassifier(random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42),
    'SVM': SVC(probability=True, random_state=42),
    'ANN': MLPClassifier(max_iter=200, random_state=42),
    'k-NN': KNeighborsClassifier(n_neighbors=5)
}

# Execute RandomizedSearchCV for hyperparameter optimization
optimizers = {
    'Random Forest': RandomizedSearchCV(models['Random Forest'], param_distributions=param_dist_rf, n_iter=10, cv=cv, random_state=42, n_jobs=-1),
    'Gradient Boosting': RandomizedSearchCV(models['Gradient Boosting'], param_distributions=param_dist_gb, n_iter=10, cv=cv, random_state=42, n_jobs=-1)
}

# Evaluate each model
results = []

for name, model in models.items():
    print(f"Training and evaluating model: {name}")
    
    if name in optimizers:
        optimized_model = optimizers[name]
        optimized_model.fit(X_train_balanced, y_train_balanced)
        best_model = optimized_model.best_estimator_
        print(f"Best model for {name}: {optimized_model.best_params_}")
    else:
        best_model = model
        best_model.fit(X_train_balanced, y_train_balanced)
    
    y_pred = best_model.predict(X_test)
    
    # Check if predict_proba is available
    if hasattr(best_model, "predict_proba"):
        y_pred_proba = best_model.predict_proba(X_test)
        if y_pred_proba.shape[1] > 1:
            y_pred_proba = y_pred_proba[:, 1]  # Get the probability of the positive class
        else:
            y_pred_proba = y_pred_proba[:, 0]  # Only one class exists
    else:
        y_pred_proba = y_pred  # For models like SVM without predict_proba

    # Calculate AUC-ROC, if possible
    if len(np.unique(y_test)) > 1:
        auc = roc_auc_score(y_test, y_pred_proba)
    else:
        auc = None
    
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='macro')
    precision = precision_score(y_test, y_pred, average='macro')
    recall = recall_score(y_test, y_pred, average='macro')

    results.append({
        'Model': name,
        'AUC-ROC': auc,
        'Accuracy': acc,
        'F1 Score': f1,
        'Precision': precision,
        'Recall': recall
    })

# Create a table with the results
results_df = pd.DataFrame(results)
print(results_df)

# Identify the best model
best_model_name = results_df.loc[results_df['F1 Score'].idxmax()]['Model']
print(f'The best model is: {best_model_name}')

# Adjust decision threshold for the best model
best_model = models[best_model_name]
best_model.fit(X_train_balanced, y_train_balanced)
if hasattr(best_model, "predict_proba"):
    y_pred_proba = best_model.predict_proba(X_test)
    if y_pred_proba.shape[1] > 1:
        y_pred_proba = y_pred_proba[:, 1]  # Get the probability of the positive class
    else:
        y_pred_proba = y_pred_proba[:, 0]  # Only one class exists
else:
    y_pred_proba = y_pred  # For models like SVM without predict_proba

# Adjust the decision threshold to optimize F1 Score
thresholds = [0.1, 0.2, 0.3, 0.4, 0.5]
best_threshold = 0.5
best_f1 = 0

for threshold in thresholds:
    y_pred_adjusted = (y_pred_proba >= threshold).astype(int)
    f1 = f1_score(y_test, y_pred_adjusted, average='macro')
    if f1 > best_f1:
        best_f1 = f1
        best_threshold = threshold

print(f"Best threshold: {best_threshold} with F1 Score: {best_f1}")

y_pred_adjusted = (y_pred_proba >= best_threshold).astype(int)

# Evaluate the model with the new decision threshold
print("Results after adjusting the decision threshold:")
print(classification_report(y_test, y_pred_adjusted))

# Predict susceptibility using the best model with the adjusted threshold
y_pred_proba_all = best_model.predict_proba(X)
if y_pred_proba_all.shape[1] > 1:
    y_pred_proba_all = y_pred_proba_all[:, 1]
else:
    y_pred_proba_all = y_pred_proba_all[:, 0]

susceptibility_adjusted = (y_pred_proba_all >= best_threshold).astype(int)
susceptibility_raster = susceptibility_adjusted.reshape((rows, cols))

# Save the result as a new raster file in GeoTIFF format
output_file = os.path.join(data_dir, 'susceptibility_map.tif')

with rasterio.open(
    output_file, 'w',
    driver='GTiff',
    height=rows,
    width=cols,
    count=1,
    dtype=rasterio.int32,
    crs=reference_crs,
    transform=reference_transform,
    compress='lzw'
) as dst:
    dst.write(susceptibility_raster.astype(rasterio.int32), 1)

print(f'Susceptibility map saved in: {output_file}')

# Display the susceptibility map
plt.figure(figsize=(10, 10))
plt.imshow(susceptibility_raster, cmap='viridis')
plt.colorbar()
plt.title('Landslide Susceptibility Map')
plt.show()
