import rasterio
import numpy as np
import os
from rasterio.warp import reproject, Resampling
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV
from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, classification_report
import pandas as pd
from imblearn.over_sampling import SMOTE
from scipy.stats import randint as sp_randint
import matplotlib.pyplot as plt

# Definir o caminho da pasta onde os arquivos estão no Colab
data_dir = '/content/'

# Lista dos arquivos a serem utilizados no modelo
arquivos = [
    'SMI.tif', 'Slope_Degree.tif', 'Saturation.tif', 'Relief_Dissection.tif', 'Geomorphology.tif', 'Geology.tif', 'TPI.tif', 'Cicatrizes.tif'
]
cicatrizes_arquivo = 'Cicatrizes.tif'

# Função para carregar e reamostrar um raster para o shape de referência
def carregar_reamostrar_raster(file_path, shape_ref, transform_ref, crs_ref):
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Arquivo não encontrado: {file_path}")
    
    with rasterio.open(file_path) as src:
        data = src.read(1)
        if data.shape != shape_ref:
            out_data = np.empty(shape_ref, dtype=data.dtype)
            reproject(
                source=data,
                destination=out_data,
                src_transform=src.transform,
                src_crs=src.crs,
                dst_transform=transform_ref,
                dst_crs=crs_ref,
                resampling=Resampling.bilinear
            )
            print(f"Reamostrado {file_path} de {data.shape} para {shape_ref}")
            return out_data
        else:
            print(f"Carregado {file_path} com shape {data.shape}")
            return data

# Verifique se os arquivos estão presentes no diretório
print("Arquivos disponíveis no diretório:")
print(os.listdir(data_dir))

# Carregar a camada de cicatrizes (camada de referência)
caminho_cicatrizes = os.path.join(data_dir, cicatrizes_arquivo)
with rasterio.open(caminho_cicatrizes) as src:
    cicatrizes = src.read(1)
    referencia_transform = src.transform
    referencia_crs = src.crs
referencia_shape = cicatrizes.shape

# Carregar e reamostrar as outras camadas raster para o shape de referência
camadas = {}
for arquivo in arquivos:
    caminho = os.path.join(data_dir, arquivo)
    if arquivo != cicatrizes_arquivo:  # Não precisa reamostrar a camada de cicatrizes
        data = carregar_reamostrar_raster(caminho, referencia_shape, referencia_transform, referencia_crs)
        camadas[arquivo] = data

# Preparar os dados de entrada para o modelo
rows, cols = referencia_shape
X = np.zeros((rows * cols, len(camadas)))

for i, (nome, dados) in enumerate(camadas.items()):
    X[:, i] = dados.ravel()

# Usar a camada de cicatrizes como variável alvo
y = cicatrizes.ravel()

# Verificar a distribuição de classes em y
unique, counts = np.unique(y, return_counts=True)
print(f"Distribuição de classes em y: {dict(zip(unique, counts))}")

# Amostragem de dados para reduzir o tempo de processamento
sample_size = 5000  # Ajuste o tamanho da amostra conforme necessário
indices = np.random.choice(X.shape[0], sample_size, replace=False)
X_sample = X[indices]
y_sample = y[indices]

# Dividir os dados em treinamento e teste, garantindo estratificação
X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.3, random_state=42, stratify=y_sample)

# Verificar a distribuição de classes em y_test
unique_test, counts_test = np.unique(y_test, return_counts=True)
print(f"Distribuição de classes em y_test: {dict(zip(unique_test, counts_test))}")

# Aplicar SMOTE para balanceamento de classes
if len(np.unique(y_train)) > 1:  # Garantir que existam pelo menos duas classes
    min_class_samples = np.min(np.bincount(y_train))  # Conta as amostras na classe minoritária
    n_neighbors = min(5, max(1, min_class_samples - 1))  # Ajustar n_neighbors dinamicamente
    smote = SMOTE(random_state=42, k_neighbors=n_neighbors)
    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

    # Verificar a distribuição de classes após o SMOTE
    unique_train_balanced, counts_train_balanced = np.unique(y_train_balanced, return_counts=True)
    print(f"Distribuição de classes em y_train após o SMOTE: {dict(zip(unique_train_balanced, counts_train_balanced))}")
else:
    print("SMOTE não aplicado devido à falta de diversidade nas classes.")
    X_train_balanced, y_train_balanced = X_train, y_train

# Configurar validação cruzada estratificada
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Definir os hiperparâmetros para busca com RandomizedSearchCV
param_dist_rf = {
    "n_estimators": sp_randint(10, 200),
    "max_depth": sp_randint(3, 20),
    "min_samples_split": sp_randint(2, 11),
    "min_samples_leaf": sp_randint(1, 11),
    "bootstrap": [True, False]
}

param_dist_gb = {
    "n_estimators": sp_randint(10, 200),
    "learning_rate": [0.01, 0.05, 0.1, 0.2],
    "max_depth": sp_randint(3, 20),
    "min_samples_split": sp_randint(2, 11),
    "min_samples_leaf": sp_randint(1, 11)
}

# Inicializar modelos
modelos = {
    'Random Forest': RandomForestClassifier(random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42),
    'SVM': SVC(probability=True, random_state=42),
    'ANN': MLPClassifier(max_iter=200, random_state=42),
    'k-NN': KNeighborsClassifier(n_neighbors=5)
}

# Executar RandomizedSearchCV para otimização de hiperparâmetros
optimizadores = {
    'Random Forest': RandomizedSearchCV(modelos['Random Forest'], param_distributions=param_dist_rf, n_iter=10, cv=cv, random_state=42, n_jobs=-1),
    'Gradient Boosting': RandomizedSearchCV(modelos['Gradient Boosting'], param_distributions=param_dist_gb, n_iter=10, cv=cv, random_state=42, n_jobs=-1)
}

# Avaliar cada modelo
resultados = []

for nome, modelo in modelos.items():
    print(f"Treinando e avaliando o modelo: {nome}")
    
    if nome in optimizadores:
        modelo_otimizado = optimizadores[nome]
        modelo_otimizado.fit(X_train_balanced, y_train_balanced)
        melhor_modelo = modelo_otimizado.best_estimator_
        print(f"Melhor modelo para {nome}: {modelo_otimizado.best_params_}")
    else:
        melhor_modelo = modelo
        melhor_modelo.fit(X_train_balanced, y_train_balanced)
    
    y_pred = melhor_modelo.predict(X_test)
    
    # Verificar se predict_proba está disponível
    if hasattr(melhor_modelo, "predict_proba"):
        y_pred_proba = melhor_modelo.predict_proba(X_test)
        if y_pred_proba.shape[1] > 1:
            y_pred_proba = y_pred_proba[:, 1]  # Pegue a probabilidade da classe positiva
        else:
            y_pred_proba = y_pred_proba[:, 0]  # Só existe uma classe
    else:
        y_pred_proba = y_pred  # Para modelos como SVM sem predict_proba

    # Calcular AUC-ROC, se possível
    if len(np.unique(y_test)) > 1:
        auc = roc_auc_score(y_test, y_pred_proba)
    else:
        auc = None
    
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='macro')
    precision = precision_score(y_test, y_pred, average='macro')
    recall = recall_score(y_test, y_pred, average='macro')

    resultados.append({
        'Modelo': nome,
        'AUC-ROC': auc,
        'Accuracy': acc,
        'F1 Score': f1,
        'Precision': precision,
        'Recall': recall
    })

# Criar uma tabela com os resultados
resultados_df = pd.DataFrame(resultados)
print(resultados_df)

# Identificar o melhor modelo
melhor_modelo_nome = resultados_df.loc[resultados_df['F1 Score'].idxmax()]['Modelo']
print(f'O melhor modelo é: {melhor_modelo_nome}')

# Ajuste de limiar de decisão para o melhor modelo
melhor_modelo = modelos[melhor_modelo_nome]
melhor_modelo.fit(X_train_balanced, y_train_balanced)
if hasattr(melhor_modelo, "predict_proba"):
    y_pred_proba = melhor_modelo.predict_proba(X_test)
    if y_pred_proba.shape[1] > 1:
        y_pred_proba = y_pred_proba[:, 1]  # Pegue a probabilidade da classe positiva
    else:
        y_pred_proba = y_pred_proba[:, 0]  # Só existe uma classe
else:
    y_pred_proba = y_pred  # Para modelos como SVM sem predict_proba

# Ajustar o limiar de decisão para otimizar F1 Score
thresholds = [0.1, 0.2, 0.3, 0.4, 0.5]
best_threshold = 0.5
best_f1 = 0

for threshold in thresholds:
    y_pred_adjusted = (y_pred_proba >= threshold).astype(int)
    f1 = f1_score(y_test, y_pred_adjusted, average='macro')
    if f1 > best_f1:
        best_f1 = f1
        best_threshold = threshold

print(f"Melhor limiar: {best_threshold} com F1 Score: {best_f1}")

y_pred_adjusted = (y_pred_proba >= best_threshold).astype(int)

# Avaliar o modelo com o novo limiar
print("Resultados após ajuste do limiar de decisão:")
print(classification_report(y_test, y_pred_adjusted))

# Prever a susceptibilidade usando o melhor modelo com o limiar ajustado
y_pred_proba_all = melhor_modelo.predict_proba(X)
if y_pred_proba_all.shape[1] > 1:
    y_pred_proba_all = y_pred_proba_all[:, 1]
else:
    y_pred_proba_all = y_pred_proba_all[:, 0]

susceptibilidade_adjusted = (y_pred_proba_all >= best_threshold).astype(int)
susceptibilidade_raster = susceptibilidade_adjusted.reshape((rows, cols))

# Salvar o resultado como um novo arquivo raster em formato GeoTIFF
output_file = os.path.join(data_dir, 'mapa_susceptibilidade.tif')

with rasterio.open(
    output_file, 'w',
    driver='GTiff',
    height=rows,
    width=cols,
    count=1,
    dtype=rasterio.int32,
    crs=referencia_crs,
    transform=referencia_transform,
    compress='lzw'
) as dst:
    dst.write(susceptibilidade_raster.astype(rasterio.int32), 1)

print(f'Mapa de susceptibilidade salvo em: {output_file}')

# Mostrar o mapa de susceptibilidade
plt.figure(figsize=(10, 10))
plt.imshow(susceptibilidade_raster, cmap='viridis')
plt.colorbar()
plt.title('Mapa de Susceptibilidade a Deslizamentos')
plt.show()
